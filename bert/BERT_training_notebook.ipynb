{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:00.308814Z",
     "iopub.status.busy": "2024-11-11T07:15:00.308501Z",
     "iopub.status.idle": "2024-11-11T07:15:24.488989Z",
     "shell.execute_reply": "2024-11-11T07:15:24.488174Z",
     "shell.execute_reply.started": "2024-11-11T07:15:00.308780Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datasets import Dataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import EarlyStoppingCallback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:24.491139Z",
     "iopub.status.busy": "2024-11-11T07:15:24.490538Z",
     "iopub.status.idle": "2024-11-11T07:15:24.520679Z",
     "shell.execute_reply": "2024-11-11T07:15:24.519698Z",
     "shell.execute_reply.started": "2024-11-11T07:15:24.491082Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/mlprojectdataset/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/mlprojectdataset/test.csv')\n",
    "\n",
    "with open(\"/kaggle/input/mlprojectdataset/clinical-stopwords.txt\", 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:24.522977Z",
     "iopub.status.busy": "2024-11-11T07:15:24.521960Z",
     "iopub.status.idle": "2024-11-11T07:15:24.546361Z",
     "shell.execute_reply": "2024-11-11T07:15:24.545486Z",
     "shell.execute_reply.started": "2024-11-11T07:15:24.522925Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stopwords])\n",
    "\n",
    "train_df['description'] = train_df['description'].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "test_df['description'] = test_df['description'].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['disease'])\n",
    "test_df['label'] = label_encoder.transform(test_df['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:24.549452Z",
     "iopub.status.busy": "2024-11-11T07:15:24.548843Z",
     "iopub.status.idle": "2024-11-11T07:15:25.714753Z",
     "shell.execute_reply": "2024-11-11T07:15:25.713846Z",
     "shell.execute_reply.started": "2024-11-11T07:15:24.549418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6463108487164f079bcb1a9263bbefe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae92b8d73130443c8f5dc093216e5c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7009777ac618456593a090d55e57471e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f6213b279e4af9904a020c644ec583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df06d931485c4f1bb8a3c9ee95cb62e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884b144e4f044cfc8d27113f5f54f27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased', clean_up_tokenization_spaces=False)\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples['description'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:25.716370Z",
     "iopub.status.busy": "2024-11-11T07:15:25.715974Z",
     "iopub.status.idle": "2024-11-11T07:15:25.813858Z",
     "shell.execute_reply": "2024-11-11T07:15:25.813157Z",
     "shell.execute_reply.started": "2024-11-11T07:15:25.716325Z"
    }
   },
   "outputs": [],
   "source": [
    "X_smote = train_df['description']\n",
    "y_smote = train_df['label']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "_, y_resampled = smote.fit_resample(np.zeros((len(X_smote), 1)), y_smote)  \n",
    "\n",
    "resampled_indices = []\n",
    "for class_label in np.unique(y_resampled):\n",
    "    class_indices = np.where(y_smote == class_label)[0]\n",
    "    class_resampled_indices = np.random.choice(class_indices, size=(y_resampled == class_label).sum(), replace=True)\n",
    "    resampled_indices.extend(class_resampled_indices)\n",
    "\n",
    "\n",
    "train_resampled_dataset = train_dataset.select(resampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:25.815443Z",
     "iopub.status.busy": "2024-11-11T07:15:25.815023Z",
     "iopub.status.idle": "2024-11-11T07:15:28.667952Z",
     "shell.execute_reply": "2024-11-11T07:15:28.667150Z",
     "shell.execute_reply.started": "2024-11-11T07:15:25.815395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f4ad3804a14c2aa5c04d71fc50ac17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "class_counts = train_df['label'].value_counts().sort_index()\n",
    "class_weights = torch.tensor([1.0 / count for count in class_counts])\n",
    "class_weights = class_weights.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:28.669352Z",
     "iopub.status.busy": "2024-11-11T07:15:28.669046Z",
     "iopub.status.idle": "2024-11-11T07:15:28.708282Z",
     "shell.execute_reply": "2024-11-11T07:15:28.707435Z",
     "shell.execute_reply.started": "2024-11-11T07:15:28.669320Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",         \n",
    "    save_strategy=\"epoch\",               \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,                  \n",
    "    learning_rate=2e-5,                  \n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,         \n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:28.712847Z",
     "iopub.status.busy": "2024-11-11T07:15:28.711867Z",
     "iopub.status.idle": "2024-11-11T07:15:28.758985Z",
     "shell.execute_reply": "2024-11-11T07:15:28.758038Z",
     "shell.execute_reply.started": "2024-11-11T07:15:28.712806Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.tensor(logits)\n",
    "    predictions = torch.argmax(logits_tensor, dim=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "    \n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:28.760536Z",
     "iopub.status.busy": "2024-11-11T07:15:28.760221Z",
     "iopub.status.idle": "2024-11-11T07:15:30.082610Z",
     "shell.execute_reply": "2024-11-11T07:15:30.081817Z",
     "shell.execute_reply.started": "2024-11-11T07:15:28.760504Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_resampled_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:30.086240Z",
     "iopub.status.busy": "2024-11-11T07:15:30.085924Z",
     "iopub.status.idle": "2024-11-11T07:15:30.090868Z",
     "shell.execute_reply": "2024-11-11T07:15:30.089899Z",
     "shell.execute_reply.started": "2024-11-11T07:15:30.086206Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.cuda.amp.autocast.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:15:30.092364Z",
     "iopub.status.busy": "2024-11-11T07:15:30.092001Z",
     "iopub.status.idle": "2024-11-11T07:18:35.890265Z",
     "shell.execute_reply": "2024-11-11T07:18:35.889025Z",
     "shell.execute_reply.started": "2024-11-11T07:15:30.092320Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c9efa75eb849b2a9ec27fc019079a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113774933333945, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241111_071553-r9lepbbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface/runs/r9lepbbz' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface/runs/r9lepbbz' target=\"_blank\">https://wandb.ai/pamtdaar-vellore-institute-of-technology/huggingface/runs/r9lepbbz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [392/420 02:36 < 00:11, 2.49 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.022900</td>\n",
       "      <td>2.816677</td>\n",
       "      <td>0.235849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.520100</td>\n",
       "      <td>2.361238</td>\n",
       "      <td>0.518868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.906100</td>\n",
       "      <td>1.789422</td>\n",
       "      <td>0.707547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.395700</td>\n",
       "      <td>1.389440</td>\n",
       "      <td>0.834906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.025800</td>\n",
       "      <td>1.113104</td>\n",
       "      <td>0.834906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.825400</td>\n",
       "      <td>0.880651</td>\n",
       "      <td>0.877358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.717021</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.445700</td>\n",
       "      <td>0.606941</td>\n",
       "      <td>0.910377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.535006</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.460231</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.415996</td>\n",
       "      <td>0.929245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.400643</td>\n",
       "      <td>0.910377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.383344</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.361701</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.amp.autocast('cuda', enabled=True):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:18:35.892784Z",
     "iopub.status.busy": "2024-11-11T07:18:35.892073Z",
     "iopub.status.idle": "2024-11-11T07:18:37.680314Z",
     "shell.execute_reply": "2024-11-11T07:18:37.679415Z",
     "shell.execute_reply.started": "2024-11-11T07:18:35.892730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                        allergy       0.90      0.90      0.90        10\n",
      "                      arthritis       1.00      1.00      1.00        10\n",
      "               bronchial asthma       0.91      1.00      0.95        10\n",
      "           cervical spondylosis       0.83      1.00      0.91        10\n",
      "                    chicken pox       1.00      0.80      0.89        10\n",
      "                    common cold       0.91      1.00      0.95        10\n",
      "                         dengue       1.00      0.80      0.89        10\n",
      "                       diabetes       0.78      0.70      0.74        10\n",
      "                  drug reaction       0.86      0.75      0.80         8\n",
      "               fungal infection       1.00      1.00      1.00         9\n",
      "gastroesophageal reflux disease       0.90      0.90      0.90        10\n",
      "                   hypertension       0.91      1.00      0.95        10\n",
      "                       impetigo       1.00      1.00      1.00        10\n",
      "                       jaundice       1.00      1.00      1.00         7\n",
      "                        malaria       0.91      1.00      0.95        10\n",
      "                       migraine       1.00      0.90      0.95        10\n",
      "           peptic ulcer disease       1.00      0.80      0.89        10\n",
      "                      pneumonia       1.00      1.00      1.00        10\n",
      "                      psoriasis       0.91      1.00      0.95        10\n",
      "                        typhoid       0.80      0.89      0.84         9\n",
      "        urinary tract infection       0.90      1.00      0.95         9\n",
      "                 varicose veins       1.00      1.00      1.00        10\n",
      "\n",
      "                       accuracy                           0.93       212\n",
      "                      macro avg       0.93      0.93      0.93       212\n",
      "                   weighted avg       0.93      0.93      0.93       212\n",
      "\n",
      "Test Accuracy: 0.9292452830188679\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "predictions_tensor = torch.tensor(predictions.predictions)\n",
    "pred_labels = torch.argmax(predictions_tensor, axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(test_df['label'], pred_labels, target_names=label_encoder.classes_, zero_division=0))\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(test_df['label'], pred_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:23:17.126283Z",
     "iopub.status.busy": "2024-11-11T07:23:17.125838Z",
     "iopub.status.idle": "2024-11-11T07:23:18.111276Z",
     "shell.execute_reply": "2024-11-11T07:23:18.110222Z",
     "shell.execute_reply.started": "2024-11-11T07:23:17.126244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "import torch\n",
    "\n",
    "model_save_path = './model'\n",
    "tokenizer_save_path = './tokenizer'\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(\"Model and tokenizer saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T07:23:53.265853Z",
     "iopub.status.busy": "2024-11-11T07:23:53.264986Z",
     "iopub.status.idle": "2024-11-11T07:23:53.273335Z",
     "shell.execute_reply": "2024-11-11T07:23:53.272336Z",
     "shell.execute_reply.started": "2024-11-11T07:23:53.265812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoder saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "label_encoder_save_path = './label_encoder.pkl'\n",
    "\n",
    "joblib.dump(label_encoder, label_encoder_save_path)\n",
    "\n",
    "print(\"Label encoder saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6057432,
     "sourceId": 9868332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
